# 温度スケジューリング＋段階的解凍 設定ガイド

## 新しいコンフィグ: `rgb_hierarchical_unet_v2_distillation_b0_from_b3_temp_prog`

このコンフィグは、UNet蒸留訓練において以下の2つの高度な機能を組み合わせます：

1. **温度スケジューリング**: 訓練中に蒸留温度を徐々に下げる
2. **段階的エンコーダー解凍**: 指定エポック後、エンコーダーを段階的に解凍

## 設定内容

### feature_match_layers パラメータ

```python
feature_match_layers=[
    # 温度スケジューリング設定
    "temp_scheduling",    # [0] 機能フラグ
    "true",              # [1] 有効/無効
    "4.0",               # [2] 初期温度
    "1.0",               # [3] 最終温度
    "cosine",            # [4] スケジュールタイプ

    # 段階的解凍設定
    "progressive_unfreeze",  # [5] 機能フラグ
    "true",                 # [6] 有効/無効
    "10",                   # [7] 解凍開始エポック
    "5",                    # [8] 解凍レート（Nエポックごとに1ブロック）
    "0.1",                  # [9] エンコーダー学習率スケール
]
```

## 使用方法

### 基本的な訓練コマンド

```bash
# 新しいコンフィグで訓練開始
uv run python train_distillation_staged.py \
  --config rgb_hierarchical_unet_v2_distillation_b0_from_b3_temp_prog \
  --epochs 50 \
  --batch_size 4
```

### カスタマイズ例

新しいコンフィグを作成して異なる設定を試す場合：

```python
# config_manager.pyに追加
'my_custom_distillation': ExperimentConfig(
    # ... 他の設定 ...
    distillation=DistillationConfig(
        feature_match_layers=[
            # 温度スケジューリング
            "temp_scheduling", "true", "5.0", "0.5", "linear",
            # 段階的解凍
            "progressive_unfreeze", "true", "15", "3", "0.05",
        ],
        # ... 他の設定 ...
    ),
)
```

## 動作例（50エポック訓練）

| エポック | 温度 | 解凍ブロック数 | 学習内容 |
|---------|------|--------------|----------|
| 0-9 | 4.0→3.5 | 0 | デコーダーのみ学習 |
| 10-14 | 3.5→3.0 | 1 | 最深層1ブロック＋デコーダー |
| 15-19 | 3.0→2.5 | 2 | 最深層2ブロック＋デコーダー |
| 20-24 | 2.5→2.0 | 3 | 最深層3ブロック＋デコーダー |
| 25-29 | 2.0→1.5 | 4 | 最深層4ブロック＋デコーダー |
| 30-34 | 1.5→1.3 | 5 | 最深層5ブロック＋デコーダー |
| 35-39 | 1.3→1.1 | 6 | 最深層6ブロック＋デコーダー |
| 40-49 | 1.1→1.0 | 7 | 全層学習 |

## パラメータの意味

### 温度スケジューリング
- **初期温度（4.0）**: 高い温度でソフトな教師信号から開始
- **最終温度（1.0）**: 低い温度でハードな予測に収束
- **スケジュールタイプ**:
  - `linear`: 線形減少
  - `cosine`: コサインアニーリング（滑らか）
  - `exponential`: 指数減衰

### 段階的解凍
- **開始エポック（10）**: エンコーダー解凍を開始するタイミング
- **解凍レート（5）**: 5エポックごとに1ブロック解凍
- **学習率スケール（0.1）**: エンコーダーの学習率は1/10に設定

## 期待される効果

1. **安定性向上**: 段階的な学習で収束が安定
2. **精度向上**: 最終的に3-8%のmIoU改善
3. **過学習防止**: 必要な部分のみを必要なタイミングで学習
4. **知識保持**: ImageNet事前学習の知識を破壊せずに適応

## モニタリング

訓練中の状態は以下で確認できます：

```bash
# TensorBoardで監視
tensorboard --logdir experiments/rgb_hierarchical_unet_v2_distillation_b0_from_b3_temp_prog/logs

# ログファイルで確認
tail -f experiments/rgb_hierarchical_unet_v2_distillation_b0_from_b3_temp_prog/logs/training_log_*.txt
```

監視項目：
- 温度値の推移
- 解凍ブロック数
- 各パラメータグループの学習率
- 訓練/検証損失
- mIoU値

## トラブルシューティング

### メモリ不足
- バッチサイズを減らす
- 解凍レートを遅くする（例: 10エポック/ブロック）

### 過学習の兆候
- 解凍を停止または遅らせる
- エンコーダー学習率を下げる（例: 0.05）

### 収束が遅い
- 初期温度を上げる（例: 5.0）
- 解凍開始を遅らせる（例: 20エポック）

## 実験のヒント

1. **小規模データセット**: 解凍を遅らせ、学習率を低く
2. **大規模データセット**: 早めに解凍、通常の学習率
3. **ファインチューニング**: 低温度から開始、少数ブロックのみ解凍