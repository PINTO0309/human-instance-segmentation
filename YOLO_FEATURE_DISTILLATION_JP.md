# YOLOv9特徴蒸留パイプライン

## 概要

本ドキュメントでは、人物セグメンテーションタスクにおいて、YOLO特徴アライメントとUNet教師-生徒蒸留を組み合わせた知識蒸留パイプラインについて説明します。

## アーキテクチャ概要

### 訓練時パイプライン

```
入力画像 (640×640, ImageNet正規化済み)
        ├─────────────────┬─────────────────┐
        │                 │                 │
        v                 v                 v
   逆正規化          教師UNet B3       生徒UNet B0
   [0,1]範囲へ       (固定)           (デコーダのみ学習)
        │                 │                 │
        v                 │                 v
   YOLOv9 ONNX           │            特徴@80×80
   (固定)                │            (40チャンネル)
        │                 │                 │
        v                 v                 v
  特徴@80×80        セグメンテーション  投影層
  (1024チャンネル)   出力              (40→768→1024)
        │                 │                 │
        └─────────────────┴─────────────────┘
                          │
                          v
                      損失計算
```

### 推論時パイプライン

```
入力画像 (640×640)
        │
        v
  生徒UNet B0
  (投影層なし)
        │
        v
  セグメンテーション出力
```

## コンポーネント詳細

### 1. 教師モデル: EfficientNet-B3搭載UNet

- **アーキテクチャ**: EfficientNet-B3エンコーダを持つ標準的なUNet
- **重み**: 人物セグメンテーションタスクで事前学習済み
- **役割**: セグメンテーションの教師信号を提供
- **状態**: 訓練時は固定（学習しない）
- **入力**: 640×640画像（ImageNet正規化済み）
- **出力**: バイナリセグメンテーションマスク（1×640×640）

### 2. 生徒モデル: EfficientNet-B0搭載UNet

- **アーキテクチャ**: EfficientNet-B0エンコーダを持つ軽量UNet
- **エンコーダ**: 固定（ImageNet事前学習済み）
- **デコーダ**: 学習可能
- **特徴抽出点**: レイヤー3（40×80×80）
- **入力**: 640×640画像（ImageNet正規化済み）
- **出力**: バイナリセグメンテーションマスク（1×640×640）

### 3. YOLOv9特徴抽出器

- **モデル**: YOLOv9-E全身検出器
- **形式**: ONNX最適化済み
- **対象レイヤー**: `segmentation_model_34_Concat_output_0`
- **出力形状**: 1024×80×80
- **入力正規化**: 単純な[0,1]範囲（ImageNet正規化なし）
- **役割**: 人物認識に特化した豊富な特徴を蒸留用に提供

### 4. 特徴投影層

- **アーキテクチャ**: 
  ```
  Conv2d(40, 768, kernel_size=1)
  BatchNorm2d(768)
  ReLU()
  Conv2d(768, 1024, kernel_size=1)
  ```
- **目的**: 生徒の特徴をYOLO特徴に整合させる
- **訓練時**: 最適化対象に含まれる
- **推論時**: 削除される（不要）

## 損失関数

### 1. 出力蒸留損失

#### KLダイバージェンス損失
- 教師と生徒の出力分布の差を測定
- バイナリセグメンテーション用の計算式:
  ```
  KL = p * log(p/q) + (1-p) * log((1-p)/(1-q))
  ここで p = 教師の確率, q = 生徒の確率
  ```
- 温度スケーリング: T=3.0
- 重み: 1.0

#### MSE損失
- 教師と生徒の出力を直接マッチング
- 重み: 0.5

#### BCE損失
- 正解データとのバイナリクロスエントロピー
- 重み: 0.5

#### Dice損失
- 正解データとの重なりを測定
- 重み: 1.0

### 2. 特徴アライメント損失

- **種類**: YOLO特徴と投影済み生徒特徴間のMSE
- **解像度**: 80×80
- **チャンネル数**: 1024
- **重み**: 0.5（調整可能）

### 総合損失
```python
total_loss = kl_weight * kl_loss + 
             mse_weight * mse_loss + 
             bce_weight * bce_loss + 
             dice_weight * dice_loss + 
             feature_weight * feature_loss
```

## データフロー

### 訓練フェーズ

1. **入力処理**
   - 画像読み込み（640×640）
   - データ拡張の適用（有効な場合）
   - ImageNet統計による正規化

2. **特徴抽出**
   - YOLO用に逆正規化（ImageNet正規化を除去）
   - YOLO特徴の抽出（1024×80×80）
   - 生徒特徴をレイヤー3から抽出（40×80×80）
   - 生徒特徴を1024チャンネルに投影

3. **順伝播**
   - 教師がセグメンテーションマスクを生成
   - 生徒がセグメンテーションマスクを生成
   - すべての損失要素を計算

4. **逆伝播**
   - 生徒デコーダパラメータのみ更新
   - 投影層パラメータを更新
   - 教師とエンコーダは固定のまま

### 推論フェーズ

1. **簡略化されたパイプライン**
   - 入力画像 → 生徒UNet B0 → セグメンテーション
   - YOLOモデル不要
   - 投影層不要
   - 教師モデル不要

2. **性能上の利点**
   - モデルサイズの削減（B0 vs B3）
   - 推論速度の向上
   - メモリ使用量の削減

## 設定

### モデル設定
```python
{
  "student_encoder": "timm-efficientnet-b0",
  "teacher_checkpoint": "ext_extractor/2020-09-23a.pth",
  "yolo_onnx_path": "ext_extractor/yolov9_e_wholebody25_Nx3x640x640_featext_optimized.onnx",
  "yolo_target_layer": "segmentation_model_34_Concat_output_0",
  "projection_hidden_dim": 768
}
```

### 訓練設定
```python
{
  "learning_rate": 1e-4,
  "batch_size": 4,
  "epochs": 50,
  "optimizer": "AdamW",
  "scheduler": "cosine",
  "temperature": 3.0
}
```

### 損失重み
```python
{
  "kl_weight": 1.0,
  "mse_weight": 0.5,
  "bce_weight": 0.5,
  "dice_weight": 1.0,
  "feature_weight": 0.5
}
```

## 主要な設計判断

### 1. 特徴解像度の一致
- 生徒特徴を80×80解像度（レイヤー3）で抽出
- YOLO特徴解像度と完全に一致
- アップ/ダウンサンプリングによるアーティファクトを回避

### 2. 正規化の処理
- モデルごとに異なる正規化を使用:
  - UNetモデル: ImageNet正規化
  - YOLO: 単純な[0,1]正規化
- YOLO推論前に逆正規化を適用

### 3. 投影層の設計
- 隠れ次元を持つ2段階投影
- 訓練安定性のためのBatchNorm
- 効率化のため推論時は削除

### 4. 教師-生徒アーキテクチャ
- 教師: B3（大規模、高精度）
- 生徒: B0（小規模、高速）
- 精度と効率のバランス

## 学習コマンド

```bash
# フルデータセットでの学習
uv run python train_yolo_feature_distillation.py \
  --config rgb_unet_yolo_feature_distillation_b0_from_b3 \
  --epochs 50 \
  --batch_size 4 \
  --feature_weight 0.5

# 小規模データセットでのクイックテスト
uv run python train_yolo_feature_distillation.py \
  --config rgb_unet_yolo_feature_distillation_b0_from_b3 \
  --epochs 1 \
  --batch_size 2
```

## 期待される結果

### 評価指標
- 生徒mIoU: 約0.65-0.70（教師の0.89に接近）
- 教師との一致率: 85%以上
- 特徴損失: 収束後1.0未満
- KLダイバージェンス: 0.1-1.0の範囲

### モデルサイズ
- 教師（B3）: 約40MB
- 生徒（B0）: 約20MB
- 削減率: 約50%

### 推論速度
- 教師: 約50ms/画像
- 生徒: 約20ms/画像
- 高速化: 約2.5倍

## 利点

1. **知識転移**: 生徒は教師の出力とYOLOの人物特化特徴の両方から学習
2. **効率性**: 推論時は軽量な生徒モデルのみが必要
3. **精度**: YOLO特徴が追加の人物検出知識を提供
4. **柔軟性**: 特徴重みを調整して蒸留源のバランスを取ることが可能

## 制限事項

1. **訓練の複雑さ**: 訓練時に3つのモデルを管理する必要がある
2. **メモリ使用量**: 訓練時に3つのモデルすべてを読み込む必要がある
3. **特徴アライメント**: 固定的な投影アーキテクチャがすべてのケースに最適とは限らない

## 温度スケジューリング

段階的蒸留をサポートしており、訓練中に温度を徐々に下げることができます：

### 設定方法
config_manager.pyの`feature_match_layers`に以下のパラメータを追加：
```python
feature_match_layers=[
    "segmentation_model_34_Concat_output_0",  # YOLOターゲットレイヤー
    "ext_extractor/yolov9_e_wholebody25.onnx",  # ONNX パス
    "mse",    # 特徴損失タイプ
    "0.5",    # 特徴損失重み
    "768",    # 投影隠れ次元
    "true",   # 温度スケジューリングを有効化
    "3.0",    # 初期温度
    "1.0",    # 最終温度
    "cosine", # スケジュールタイプ (linear/cosine/exponential)
]
```

### スケジュールタイプ
- **linear**: 線形補間（初期温度から最終温度まで均等に減少）
- **cosine**: コサインアニーリング（滑らかな減少カーブ）
- **exponential**: 指数減衰（急速に減少後、緩やかに）

### 効果
- **訓練初期**: 高い温度でソフトなターゲットから学習
- **訓練後期**: 低い温度でハードなターゲットに近づく
- **利点**: より安定した収束と最終精度の向上

## 今後の改善案

1. **動的特徴選択**: 使用するYOLOレイヤーを学習により決定
2. **アテンション機構**: 重要な空間領域に重み付け
3. **マルチスケール特徴**: 異なる解像度の複数のYOLOレイヤーを使用
4. **特徴適応**: タスク固有のYOLO特徴変換を学習

## 実装ファイル構成

```
human-edge-detection/
├── src/human_edge_detection/
│   └── advanced/
│       └── unet_yolo_feature_distillation.py  # モデル定義
├── train_yolo_feature_distillation.py         # 訓練スクリプト
├── experiments/
│   └── rgb_unet_yolo_feature_distillation_b0_from_b3/
│       ├── checkpoints/                       # モデルチェックポイント
│       ├── logs/                              # 訓練ログ
│       └── visualizations/                    # 可視化結果
└── YOLO_FEATURE_DISTILLATION_JP.md           # このドキュメント
```

## トラブルシューティング

### よくある問題と解決策

1. **KL損失が異常に大きい場合**
   - 温度パラメータを確認（デフォルト: 3.0）
   - バイナリKL計算が正しく実装されているか確認

2. **特徴損失が0になる場合**
   - バリデーション時も`extract_features=True`になっているか確認
   - YOLO入力の正規化が正しいか確認

3. **メモリ不足エラー**
   - バッチサイズを小さくする
   - 混合精度訓練を有効化（`--mixed_precision`）

4. **収束が遅い場合**
   - 特徴重みを調整（`--feature_weight`）
   - 学習率スケジューラを確認