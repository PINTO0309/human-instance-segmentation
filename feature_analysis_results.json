[
  {
    "model_name": "yolov9_n_wholebody25_Nx3x640x640_featext_optimized.onnx",
    "input_shape": [
      1,
      3,
      640,
      640
    ],
    "num_outputs": 4,
    "outputs": [
      {
        "index": 0,
        "name": "segmentation_model_22_Concat_output_0",
        "shape": [
          1,
          89,
          80,
          80
        ],
        "channels": 89,
        "spatial_size": "80x80",
        "total_params": 569600,
        "receptive_field_estimate": "Medium (balanced)"
      },
      {
        "index": 1,
        "name": "segmentation_model_14_Concat_output_0",
        "shape": [
          1,
          80,
          80,
          80
        ],
        "channels": 80,
        "spatial_size": "80x80",
        "total_params": 512000,
        "receptive_field_estimate": "Medium (balanced)"
      },
      {
        "index": 2,
        "name": "segmentation_model_2_cv3_act_Mul_output_0",
        "shape": [
          1,
          8,
          160,
          160
        ],
        "channels": 8,
        "spatial_size": "160x160",
        "total_params": 204800,
        "receptive_field_estimate": "Medium-small (fine features)"
      },
      {
        "index": 3,
        "name": "segmentation_model_11_Concat_output_0",
        "shape": [
          1,
          112,
          40,
          40
        ],
        "channels": 112,
        "spatial_size": "40x40",
        "total_params": 179200,
        "receptive_field_estimate": "Medium-large (context)"
      }
    ],
    "success": true
  },
  {
    "model_name": "yolov9_t_wholebody25_Nx3x640x640_featext_optimized.onnx",
    "input_shape": [
      1,
      3,
      640,
      640
    ],
    "num_outputs": 5,
    "outputs": [
      {
        "index": 0,
        "name": "segmentation_model_2_Concat_output_0",
        "shape": [
          1,
          64,
          160,
          160
        ],
        "channels": 64,
        "spatial_size": "160x160",
        "total_params": 1638400,
        "receptive_field_estimate": "Medium-small (fine features)"
      },
      {
        "index": 1,
        "name": "segmentation_model_14_Concat_output_0",
        "shape": [
          1,
          160,
          80,
          80
        ],
        "channels": 160,
        "spatial_size": "80x80",
        "total_params": 1024000,
        "receptive_field_estimate": "Medium (balanced)"
      },
      {
        "index": 2,
        "name": "segmentation_model_11_Concat_output_0",
        "shape": [
          1,
          224,
          40,
          40
        ],
        "channels": 224,
        "spatial_size": "40x40",
        "total_params": 358400,
        "receptive_field_estimate": "Medium-large (context)"
      },
      {
        "index": 3,
        "name": "segmentation_model_0_conv_Conv_output_0",
        "shape": [
          1,
          16,
          320,
          320
        ],
        "channels": 16,
        "spatial_size": "320x320",
        "total_params": 1638400,
        "receptive_field_estimate": "Small (local details)"
      },
      {
        "index": 4,
        "name": "segmentation_model_8_Concat_output_0",
        "shape": [
          1,
          256,
          20,
          20
        ],
        "channels": 256,
        "spatial_size": "20x20",
        "total_params": 102400,
        "receptive_field_estimate": "Large (global context)"
      }
    ],
    "success": true
  },
  {
    "model_name": "yolov9_s_wholebody25_Nx3x640x640_featext_optimized.onnx",
    "input_shape": [
      1,
      3,
      640,
      640
    ],
    "num_outputs": 5,
    "outputs": [
      {
        "index": 0,
        "name": "segmentation_model_11_Concat_output_0",
        "shape": [
          1,
          448,
          40,
          40
        ],
        "channels": 448,
        "spatial_size": "40x40",
        "total_params": 716800,
        "receptive_field_estimate": "Medium-large (context)"
      },
      {
        "index": 1,
        "name": "segmentation_model_14_Concat_output_0",
        "shape": [
          1,
          320,
          80,
          80
        ],
        "channels": 320,
        "spatial_size": "80x80",
        "total_params": 2048000,
        "receptive_field_estimate": "Medium (balanced)"
      },
      {
        "index": 2,
        "name": "segmentation_model_8_Concat_output_0",
        "shape": [
          1,
          512,
          20,
          20
        ],
        "channels": 512,
        "spatial_size": "20x20",
        "total_params": 204800,
        "receptive_field_estimate": "Large (global context)"
      },
      {
        "index": 3,
        "name": "segmentation_model_2_Concat_output_0",
        "shape": [
          1,
          128,
          160,
          160
        ],
        "channels": 128,
        "spatial_size": "160x160",
        "total_params": 3276800,
        "receptive_field_estimate": "Medium-small (fine features)"
      },
      {
        "index": 4,
        "name": "segmentation_model_0_act_Mul_output_0",
        "shape": [
          1,
          32,
          320,
          320
        ],
        "channels": 32,
        "spatial_size": "320x320",
        "total_params": 3276800,
        "receptive_field_estimate": "Small (local details)"
      }
    ],
    "success": true
  },
  {
    "model_name": "yolov9_e_wholebody25_Nx3x640x640_featext_optimized.onnx",
    "input_shape": [
      1,
      3,
      640,
      640
    ],
    "num_outputs": 5,
    "outputs": [
      {
        "index": 0,
        "name": "segmentation_model_3_Concat_output_0",
        "shape": [
          1,
          256,
          160,
          160
        ],
        "channels": 256,
        "spatial_size": "160x160",
        "total_params": 6553600,
        "receptive_field_estimate": "Medium-small (fine features)"
      },
      {
        "index": 1,
        "name": "segmentation_model_19_Concat_output_0",
        "shape": [
          1,
          256,
          160,
          160
        ],
        "channels": 256,
        "spatial_size": "160x160",
        "total_params": 6553600,
        "receptive_field_estimate": "Medium-small (fine features)"
      },
      {
        "index": 2,
        "name": "segmentation_model_5_Concat_output_0",
        "shape": [
          1,
          512,
          80,
          80
        ],
        "channels": 512,
        "spatial_size": "80x80",
        "total_params": 3276800,
        "receptive_field_estimate": "Medium (balanced)"
      },
      {
        "index": 3,
        "name": "segmentation_model_22_Concat_output_0",
        "shape": [
          1,
          512,
          80,
          80
        ],
        "channels": 512,
        "spatial_size": "80x80",
        "total_params": 3276800,
        "receptive_field_estimate": "Medium (balanced)"
      },
      {
        "index": 4,
        "name": "segmentation_model_34_Concat_output_0",
        "shape": [
          1,
          1024,
          80,
          80
        ],
        "channels": 1024,
        "spatial_size": "80x80",
        "total_params": 6553600,
        "receptive_field_estimate": "Medium (balanced)"
      }
    ],
    "success": true
  },
  {
    "model_name": "yolov9_c_wholebody25_Nx3x640x640_featext_optimized.onnx",
    "input_shape": [
      1,
      3,
      640,
      640
    ],
    "num_outputs": 7,
    "outputs": [
      {
        "index": 0,
        "name": "segmentation_model_4_Concat_output_0",
        "shape": [
          1,
          512,
          80,
          80
        ],
        "channels": 512,
        "spatial_size": "80x80",
        "total_params": 3276800,
        "receptive_field_estimate": "Medium (balanced)"
      },
      {
        "index": 1,
        "name": "segmentation_model_5_Concat_output_0",
        "shape": [
          1,
          512,
          40,
          40
        ],
        "channels": 512,
        "spatial_size": "40x40",
        "total_params": 819200,
        "receptive_field_estimate": "Medium-large (context)"
      },
      {
        "index": 2,
        "name": "segmentation_model_2_Concat_output_0",
        "shape": [
          1,
          256,
          160,
          160
        ],
        "channels": 256,
        "spatial_size": "160x160",
        "total_params": 6553600,
        "receptive_field_estimate": "Medium-small (fine features)"
      },
      {
        "index": 3,
        "name": "segmentation_model_0_act_Mul_output_0",
        "shape": [
          1,
          64,
          320,
          320
        ],
        "channels": 64,
        "spatial_size": "320x320",
        "total_params": 6553600,
        "receptive_field_estimate": "Small (local details)"
      },
      {
        "index": 4,
        "name": "segmentation_model_7_Concat_output_0",
        "shape": [
          1,
          512,
          20,
          20
        ],
        "channels": 512,
        "spatial_size": "20x20",
        "total_params": 204800,
        "receptive_field_estimate": "Large (global context)"
      },
      {
        "index": 5,
        "name": "segmentation_model_4_cv4_conv_Conv_output_0",
        "shape": [
          1,
          512,
          80,
          80
        ],
        "channels": 512,
        "spatial_size": "80x80",
        "total_params": 3276800,
        "receptive_field_estimate": "Medium (balanced)"
      },
      {
        "index": 6,
        "name": "segmentation_model_4_cv4_act_Mul_output_0",
        "shape": [
          1,
          512,
          80,
          80
        ],
        "channels": 512,
        "spatial_size": "80x80",
        "total_params": 3276800,
        "receptive_field_estimate": "Medium (balanced)"
      }
    ],
    "success": true
  }
]