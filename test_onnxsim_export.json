{
  "model_type": "hierarchical",
  "checkpoint_path": "experiments/rgb_hierarchical_unet_v2_attention_r64m64_refined_contour_activecontourloss_distance_groupnorm/checkpoints/untrained_model.pth",
  "epoch": -1,
  "best_miou": 0.0,
  "config": {
    "name": "rgb_hierarchical_unet_v2_attention_r64m64_refined_contour_activecontourloss_distance_groupnorm",
    "description": "RGB Hierarchical UNet V2 Attention with GroupNorm - ROI:64, Mask:64 with Stable Refinement",
    "model": {
      "onnx_model": null,
      "num_classes": 3,
      "roi_size": 64,
      "mask_size": 64,
      "execution_provider": "tensorrt",
      "variable_roi_sizes": null,
      "use_rgb_enhancement": false,
      "rgb_enhanced_layers": [
        "layer_34"
      ],
      "use_hierarchical": false,
      "use_hierarchical_unet": false,
      "use_hierarchical_unet_v2": false,
      "use_hierarchical_unet_v3": false,
      "use_hierarchical_unet_v4": false,
      "use_class_specific_decoder": false,
      "use_external_features": false,
      "use_rgb_hierarchical": true,
      "use_attention_module": true,
      "use_boundary_refinement": false,
      "use_active_contour_loss": true,
      "use_progressive_upsampling": false,
      "use_subpixel_conv": false,
      "use_contour_detection": true,
      "use_distance_transform": true,
      "use_boundary_aware_loss": false,
      "activation_function": "relu",
      "activation_beta": 1.0,
      "normalization_type": "groupnorm",
      "normalization_groups": 8,
      "normalization_mix_ratio": 0.5
    },
    "data": {
      "train_annotation": "data/annotations/instances_train2017_person_only_no_crowd_500.json",
      "val_annotation": "data/annotations/instances_val2017_person_only_no_crowd_100.json",
      "train_img_dir": "data/images/train2017",
      "val_img_dir": "data/images/val2017",
      "data_stats": "data_analyze_full.json",
      "num_workers": 4,
      "pin_memory": true,
      "roi_padding": 0.0,
      "use_augmentation": true,
      "augmentation_prob": 0.5
    },
    "training": {
      "batch_size": 2,
      "learning_rate": 5e-05,
      "num_epochs": 100,
      "optimizer": "adamw",
      "weight_decay": 0.0001,
      "scheduler": "cosine",
      "min_lr": 1e-07,
      "warmup_epochs": 5,
      "T_0": 10,
      "T_mult": 2,
      "eta_min_restart": 1e-06,
      "gradient_clip": 1.0,
      "mixed_precision": true,
      "validate_every": 1,
      "save_every": 10,
      "early_stopping_patience": 10,
      "ce_weight": 1.0,
      "dice_weight": 1.0,
      "use_focal": false,
      "focal_gamma": 2.0
    },
    "multiscale": {
      "enabled": false,
      "target_layers": null,
      "fusion_method": "concat",
      "fusion_channels": 256
    },
    "distance_loss": {
      "enabled": false,
      "boundary_width": 5,
      "boundary_weight": 2.0,
      "instance_sep_weight": 3.0,
      "adaptive": false,
      "adaptation_rate": 0.01
    },
    "cascade": {
      "enabled": false,
      "num_stages": 3,
      "stage_weights": [
        0.3,
        0.3,
        0.4
      ],
      "share_features": true
    },
    "relational": {
      "enabled": false,
      "num_heads": 8,
      "dropout": 0.1
    },
    "auxiliary_task": {
      "enabled": true,
      "weight": 0.3,
      "mid_channels": 128,
      "pos_weight": null,
      "visualize": true
    },
    "output_dir": "experiments",
    "checkpoint_dir": "checkpoints",
    "log_dir": "logs"
  },
  "input_format": {
    "features_layer_3": "[B, 256, 160, 160] - High-resolution YOLO features",
    "features_layer_22": "[B, 512, 80, 80] - Mid-level YOLO features",
    "features_layer_34": "[B, 1024, 80, 80] - Deep YOLO features",
    "rois": "[N, 5] - ROIs in format [batch_idx, x1, y1, x2, y2]"
  },
  "note": "This model requires pre-extracted YOLO features. Use the YOLO ONNX model separately for feature extraction.",
  "output_format": {
    "masks": "[N, 3, 56, 56] - Segmentation logits for each ROI"
  }
}